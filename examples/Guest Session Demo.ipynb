{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from whylogs.app.session import start_whylabs_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sample dataset (from https://www.kaggle.com/yugagrawal95/sample-media-spends-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Calendar_Week</th>\n",
       "      <th>Paid_Views</th>\n",
       "      <th>Organic_Views</th>\n",
       "      <th>Google_Impressions</th>\n",
       "      <th>Email_Impressions</th>\n",
       "      <th>Facebook_Impressions</th>\n",
       "      <th>Affiliate_Impressions</th>\n",
       "      <th>Overall_Views</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1/6/2018</td>\n",
       "      <td>392</td>\n",
       "      <td>422</td>\n",
       "      <td>408</td>\n",
       "      <td>3.498950e+05</td>\n",
       "      <td>73580</td>\n",
       "      <td>12072</td>\n",
       "      <td>682</td>\n",
       "      <td>59417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1/13/2018</td>\n",
       "      <td>787</td>\n",
       "      <td>904</td>\n",
       "      <td>110</td>\n",
       "      <td>5.062702e+05</td>\n",
       "      <td>11804</td>\n",
       "      <td>9499</td>\n",
       "      <td>853</td>\n",
       "      <td>56806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1/20/2018</td>\n",
       "      <td>81</td>\n",
       "      <td>970</td>\n",
       "      <td>742</td>\n",
       "      <td>4.300422e+05</td>\n",
       "      <td>52232</td>\n",
       "      <td>17048</td>\n",
       "      <td>759</td>\n",
       "      <td>48715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1/27/2018</td>\n",
       "      <td>25</td>\n",
       "      <td>575</td>\n",
       "      <td>65</td>\n",
       "      <td>4.177457e+05</td>\n",
       "      <td>78640</td>\n",
       "      <td>10207</td>\n",
       "      <td>942</td>\n",
       "      <td>72047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2/3/2018</td>\n",
       "      <td>565</td>\n",
       "      <td>284</td>\n",
       "      <td>295</td>\n",
       "      <td>4.085058e+05</td>\n",
       "      <td>40561</td>\n",
       "      <td>5834</td>\n",
       "      <td>658</td>\n",
       "      <td>56235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>Z</td>\n",
       "      <td>2/1/2020</td>\n",
       "      <td>29239</td>\n",
       "      <td>25311</td>\n",
       "      <td>622406</td>\n",
       "      <td>1.459071e+06</td>\n",
       "      <td>45026</td>\n",
       "      <td>12098</td>\n",
       "      <td>53667</td>\n",
       "      <td>82707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>Z</td>\n",
       "      <td>2/8/2020</td>\n",
       "      <td>26230</td>\n",
       "      <td>28031</td>\n",
       "      <td>624409</td>\n",
       "      <td>5.342505e+05</td>\n",
       "      <td>227070</td>\n",
       "      <td>9548</td>\n",
       "      <td>53665</td>\n",
       "      <td>84503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>Z</td>\n",
       "      <td>2/15/2020</td>\n",
       "      <td>24749</td>\n",
       "      <td>31281</td>\n",
       "      <td>439362</td>\n",
       "      <td>4.227182e+05</td>\n",
       "      <td>393685</td>\n",
       "      <td>9861</td>\n",
       "      <td>55561</td>\n",
       "      <td>147325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>Z</td>\n",
       "      <td>2/22/2020</td>\n",
       "      <td>20713</td>\n",
       "      <td>30356</td>\n",
       "      <td>464178</td>\n",
       "      <td>6.085799e+05</td>\n",
       "      <td>424676</td>\n",
       "      <td>10221</td>\n",
       "      <td>49221</td>\n",
       "      <td>111525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>Z</td>\n",
       "      <td>2/29/2020</td>\n",
       "      <td>15990</td>\n",
       "      <td>26993</td>\n",
       "      <td>449032</td>\n",
       "      <td>4.390165e+05</td>\n",
       "      <td>161439</td>\n",
       "      <td>10294</td>\n",
       "      <td>42994</td>\n",
       "      <td>98187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3051 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Division Calendar_Week  Paid_Views  Organic_Views  Google_Impressions  \\\n",
       "0           A      1/6/2018         392            422                 408   \n",
       "1           A     1/13/2018         787            904                 110   \n",
       "2           A     1/20/2018          81            970                 742   \n",
       "3           A     1/27/2018          25            575                  65   \n",
       "4           A      2/3/2018         565            284                 295   \n",
       "...       ...           ...         ...            ...                 ...   \n",
       "3046        Z      2/1/2020       29239          25311              622406   \n",
       "3047        Z      2/8/2020       26230          28031              624409   \n",
       "3048        Z     2/15/2020       24749          31281              439362   \n",
       "3049        Z     2/22/2020       20713          30356              464178   \n",
       "3050        Z     2/29/2020       15990          26993              449032   \n",
       "\n",
       "      Email_Impressions  Facebook_Impressions  Affiliate_Impressions  \\\n",
       "0          3.498950e+05                 73580                  12072   \n",
       "1          5.062702e+05                 11804                   9499   \n",
       "2          4.300422e+05                 52232                  17048   \n",
       "3          4.177457e+05                 78640                  10207   \n",
       "4          4.085058e+05                 40561                   5834   \n",
       "...                 ...                   ...                    ...   \n",
       "3046       1.459071e+06                 45026                  12098   \n",
       "3047       5.342505e+05                227070                   9548   \n",
       "3048       4.227182e+05                393685                   9861   \n",
       "3049       6.085799e+05                424676                  10221   \n",
       "3050       4.390165e+05                161439                  10294   \n",
       "\n",
       "      Overall_Views   Sales  \n",
       "0               682   59417  \n",
       "1               853   56806  \n",
       "2               759   48715  \n",
       "3               942   72047  \n",
       "4               658   56235  \n",
       "...             ...     ...  \n",
       "3046          53667   82707  \n",
       "3047          53665   84503  \n",
       "3048          55561  147325  \n",
       "3049          49221  111525  \n",
       "3050          42994   98187  \n",
       "\n",
       "[3051 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some sample data\n",
    "csv_file = \"data/sample_media_spend.csv\"\n",
    "csv_dataframe = pd.read_csv(csv_file)\n",
    "csv_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by date and run whylogs on it. It'll take a moment to finish. When it's done it will display a message with a link to a page in WhyLabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging data for 1/11/2020\n",
      "Logging data for 1/12/2019\n",
      "Logging data for 1/13/2018\n",
      "Logging data for 1/18/2020\n",
      "Logging data for 1/19/2019\n",
      "Logging data for 1/20/2018\n",
      "Logging data for 1/25/2020\n",
      "Logging data for 1/26/2019\n",
      "Logging data for 1/27/2018\n",
      "Logging data for 1/4/2020\n",
      "Logging data for 1/5/2019\n",
      "Logging data for 1/6/2018\n",
      "Logging data for 10/12/2019\n",
      "Logging data for 10/13/2018\n",
      "Logging data for 10/19/2019\n",
      "Logging data for 10/20/2018\n",
      "Logging data for 10/26/2019\n",
      "Logging data for 10/27/2018\n",
      "Logging data for 10/5/2019\n",
      "Logging data for 10/6/2018\n",
      "Logging data for 11/10/2018\n",
      "Logging data for 11/16/2019\n",
      "Logging data for 11/17/2018\n",
      "Logging data for 11/2/2019\n",
      "Logging data for 11/23/2019\n",
      "Logging data for 11/24/2018\n",
      "Logging data for 11/3/2018\n",
      "Logging data for 11/30/2019\n",
      "Logging data for 11/9/2019\n",
      "Logging data for 12/1/2018\n",
      "Logging data for 12/14/2019\n",
      "Logging data for 12/15/2018\n",
      "Logging data for 12/21/2019\n",
      "Logging data for 12/22/2018\n",
      "Logging data for 12/28/2019\n",
      "Logging data for 12/29/2018\n",
      "Logging data for 12/7/2019\n",
      "Logging data for 12/8/2018\n",
      "Logging data for 2/1/2020\n",
      "Logging data for 2/10/2018\n",
      "Logging data for 2/15/2020\n",
      "Logging data for 2/16/2019\n",
      "Logging data for 2/17/2018\n",
      "Logging data for 2/2/2019\n",
      "Logging data for 2/22/2020\n",
      "Logging data for 2/23/2019\n",
      "Logging data for 2/24/2018\n",
      "Logging data for 2/29/2020\n",
      "Logging data for 2/3/2018\n",
      "Logging data for 2/8/2020\n",
      "Logging data for 2/9/2019\n",
      "Logging data for 3/10/2018\n",
      "Logging data for 3/16/2019\n",
      "Logging data for 3/17/2018\n",
      "Logging data for 3/2/2019\n",
      "Logging data for 3/23/2019\n",
      "Logging data for 3/24/2018\n",
      "Logging data for 3/3/2018\n",
      "Logging data for 3/30/2019\n",
      "Logging data for 3/31/2018\n",
      "Logging data for 3/9/2019\n",
      "Logging data for 4/13/2019\n",
      "Logging data for 4/14/2018\n",
      "Logging data for 4/20/2019\n",
      "Logging data for 4/21/2018\n",
      "Logging data for 4/27/2019\n",
      "Logging data for 4/28/2018\n",
      "Logging data for 4/6/2019\n",
      "Logging data for 4/7/2018\n",
      "Logging data for 5/11/2019\n",
      "Logging data for 5/12/2018\n",
      "Logging data for 5/18/2019\n",
      "Logging data for 5/19/2018\n",
      "Logging data for 5/25/2019\n",
      "Logging data for 5/26/2018\n",
      "Logging data for 5/4/2019\n",
      "Logging data for 5/5/2018\n",
      "Logging data for 6/1/2019\n",
      "Logging data for 6/15/2019\n",
      "Logging data for 6/16/2018\n",
      "Logging data for 6/2/2018\n",
      "Logging data for 6/22/2019\n",
      "Logging data for 6/23/2018\n",
      "Logging data for 6/29/2019\n",
      "Logging data for 6/30/2018\n",
      "Logging data for 6/8/2019\n",
      "Logging data for 6/9/2018\n",
      "Logging data for 7/13/2019\n",
      "Logging data for 7/14/2018\n",
      "Logging data for 7/20/2019\n",
      "Logging data for 7/21/2018\n",
      "Logging data for 7/27/2019\n",
      "Logging data for 7/28/2018\n",
      "Logging data for 7/6/2019\n",
      "Logging data for 7/7/2018\n",
      "Logging data for 8/10/2019\n",
      "Logging data for 8/11/2018\n",
      "Logging data for 8/17/2019\n",
      "Logging data for 8/18/2018\n",
      "Logging data for 8/24/2019\n",
      "Logging data for 8/25/2018\n",
      "Logging data for 8/3/2019\n",
      "Logging data for 8/31/2019\n",
      "Logging data for 8/4/2018\n",
      "Logging data for 9/1/2018\n",
      "Logging data for 9/14/2019\n",
      "Logging data for 9/15/2018\n",
      "Logging data for 9/21/2019\n",
      "Logging data for 9/22/2018\n",
      "Logging data for 9/28/2019\n",
      "Logging data for 9/29/2018\n",
      "Logging data for 9/7/2019\n",
      "Logging data for 9/8/2018\n",
      "You can explore your data in Observatory here: https://hub.whylabsapp.com/models/model-1/profiles/?sessionToken=session-28274\n"
     ]
    }
   ],
   "source": [
    "with start_whylabs_session(data_collection_consent=True) as session:\n",
    "    # Group each of the rows by the day they occur on using the date string in the Calendar_Week col\n",
    "    for day_string, dataframe_for_day in csv_dataframe.groupby(['Calendar_Week']):\n",
    "        # This dataset has dates of the form 9/5/2020\n",
    "        dt = datetime.strptime(day_string, '%m/%d/%Y')\n",
    "        print(f\"Logging data for {day_string}\")\n",
    "\n",
    "        # whylabs loggers are specific to the dataset's timestamp so we'll be using a different one for each\n",
    "        # date in our dataset.\n",
    "        logger = session.logger(dataset_timestamp=dt)\n",
    "\n",
    "        # log the data to the logger. The logger will write this data out in binary form when it closes, which\n",
    "        # at the end of the with block in the session's internal logic.\n",
    "        logger.log_dataframe(dataframe_for_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
