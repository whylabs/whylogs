{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3400e53",
   "metadata": {},
   "source": [
    "# Amazon SageMaker + WhyLabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f660747c-cc4e-4c4a-b503-652b956979ae",
   "metadata": {},
   "source": [
    "This example shows how to deploy a SageMaker endpoint with WhyLabs integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d78b1-edf4-4d39-aaec-dd15b5cca686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3==1.18.39 python-dotenv==0.19.0 scikit-learn==0.24.2 pandas==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47f4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import urllib.request as urllib\n",
    "from joblib import dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "from dotenv import dotenv_values\n",
    "from utils import delete_model, delete_endpoint_config, delete_endpoint, is_endpoint_running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c0b0c-da72-47bd-97d3-7df27fcc8892",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table of Contents\n",
    "- [1 - AWS Configuration](#1)\n",
    "- [2 - Train a Model](#2)\n",
    "- [3 - Custom image building and pushing to ECR](#3)\n",
    "- [4 - Create SageMaker Endpoint](#4)\n",
    "    - [a. Model Creation](#a)\n",
    "    - [b. Endpoint Config Creation](#b)\n",
    "    - [c. Endpoint Creation](#c)\n",
    "- [5 - Test Endpoint](#5)\n",
    "- [6 - Delete AWS resources](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50724df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - AWS configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4081508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_PROFILE_NAME = \"default\"\n",
    "session = boto3.session.Session(profile_name=AWS_PROFILE_NAME)\n",
    "AWS_REGION_NAME = session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e0d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = session.client(\"sts\")\n",
    "sm = session.client('sagemaker', region_name=AWS_REGION_NAME)\n",
    "AWS_ACCOUNT_ID = sts.get_caller_identity().get(\"Account\")\n",
    "DOCKER_IMAGE_NAME = \"whylabs-sagemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1fa562",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968df26-9a67-431b-b088-4df371597cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Download Iris Species dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc733fb-2568-4587-9ab9-bf55e9269c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'dataset' directory already existed. Moving forward\n"
     ]
    }
   ],
   "source": [
    "# Download Iris dataset and save it as csv\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "raw_data = urllib.urlopen(url)\n",
    "try:\n",
    "    os.mkdir(\"code/dataset/\")\n",
    "    # Save data as csv\n",
    "    with open('code/dataset/Iris.csv', 'wb') as file:\n",
    "        file.write(raw_data.read())\n",
    "        print(\"Dataset downloaded successfully!\")    \n",
    "except Exception as e:\n",
    "    print(\" 'dataset' directory already existed. Moving forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a89180-9e0c-486b-99f9-b948635cf5db",
   "metadata": {},
   "source": [
    "Split data set into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4354322-9286-432c-99d1-188a7306dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('code/dataset/Iris.csv', header=None)\n",
    "# Separating the independent variables from dependent variables\n",
    "X = data.iloc[:, 0:4].values\n",
    "y = data.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1884acc-a163-4628-a452-1ff0d54ee1c1",
   "metadata": {},
   "source": [
    "Train the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548cfbe8-b3b1-4f79-bd95-90f0717e8a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started.\n",
      "Train finished.\n",
      "Model saved as model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "print(\"Train started.\")\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Train finished.\")\n",
    "# Save the model\n",
    "dump(model, 'code/model.joblib')\n",
    "print(\"Model saved as model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da10283-70b7-42c5-b5ac-15feaed3b5e5",
   "metadata": {},
   "source": [
    "Split data set into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213ef90",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Custom image building and pushing to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df9d8b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image name whylabs-sagemaker\n",
      "Profile name default\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-1:377983720232:repository/whylabs-sagemaker\",\n",
      "            \"registryId\": \"377983720232\",\n",
      "            \"repositoryName\": \"whylabs-sagemaker\",\n",
      "            \"repositoryUri\": \"377983720232.dkr.ecr.us-east-1.amazonaws.com/whylabs-sagemaker\",\n",
      "            \"createdAt\": \"2021-09-08T17:32:14-05:00\",\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 sha256:ae478a8a0c822118d386950ba7913cd06eef785451d66abe7b01b5fbd6cd6285\n",
      "#1 transferring dockerfile: 1.50kB done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load .dockerignore\n",
      "#2 sha256:b54083463265b41c72a5dee01c386777b758184f41d547f4781fcb7c074a98f3\n",
      "#2 transferring context: 171B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/ubuntu:18.04\n",
      "#3 sha256:ae46bbb1b755529d0da663ca0256a22acd7c9fe21844946c149800baa67c4e4b\n",
      "#3 ...\n",
      "\n",
      "#4 [auth] library/ubuntu:pull token for registry-1.docker.io\n",
      "#4 sha256:98682aacae76ab9198aede26bb6cd7176e2e4b329b793163c199e86e47b639b9\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/ubuntu:18.04\n",
      "#3 sha256:ae46bbb1b755529d0da663ca0256a22acd7c9fe21844946c149800baa67c4e4b\n",
      "#3 DONE 1.9s\n",
      "\n",
      "#5 [ 1/11] FROM docker.io/library/ubuntu:18.04@sha256:9bc830af2bef73276515a29aa896eedfa7bdf4bdbc5c1063b4c457a4bbb8cd79\n",
      "#5 sha256:d1750e31869fe5a60e2fad31896f5d8b06a6c26d3a20b7f5836401e641279689\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#8 [internal] load build context\n",
      "#8 sha256:87dd8a6cfd1c874e9290b6e60bfc99fefe2c08dfd0118925266e6501d9098bed\n",
      "#8 transferring context: 21.54kB 0.0s done\n",
      "#8 DONE 0.0s\n",
      "\n",
      "#12 [ 7/11] RUN chmod +rwx /opt/ml/models\n",
      "#12 sha256:65145abc1c02ae61b8f7e3dfe0bf95ae940dad38ddfc15aad73267450577c42b\n",
      "#12 CACHED\n",
      "\n",
      "#6 [ 2/11] RUN apt-get update &&     apt-get -y upgrade &&     apt-get -y install --no-install-recommends         build-essential         curl         git         jq         libatlas-base-dev         python         python3-pip         nginx         openjdk-8-jdk-headless         unzip         wget         ca-certificates         libssl-dev libffi-dev         python3-setuptools         python3-dev     && rm -rf /var/lib/apt/lists/*\n",
      "#6 sha256:0ab5272c27e25ac9dc37c8aa604492357877b43b8f589cdc16f7f5a416ddcbe2\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 3/11] RUN pip3 install pip --upgrade\n",
      "#7 sha256:dd11d590a066a1d73ec9fba151e0baa7d733e7e0938a71ba7a2ff9b6b2af239f\n",
      "#7 CACHED\n",
      "\n",
      "#13 [ 8/11] RUN ln -sf /dev/stdout /var/log/nginx/access.log\n",
      "#13 sha256:977ada49ebe0cc2b955435fb60d677e25b6e9ea2a9e9b81401888d4172683df7\n",
      "#13 CACHED\n",
      "\n",
      "#11 [ 6/11] RUN mkdir -p /opt/ml/models\n",
      "#11 sha256:af09c7de83293c9c322e6bdec899675b777da33f346a14f155663366351abd54\n",
      "#11 CACHED\n",
      "\n",
      "#9 [ 4/11] COPY requirements.txt /requirements.txt\n",
      "#9 sha256:446556a42c76acda8d1bce7317356bd5aa49ab7e038da27dda88196b8fa1013e\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 5/11] RUN pip3 install -r /requirements.txt &&     rm /requirements.txt\n",
      "#10 sha256:19a0085981b2fb160ab15acae4c4e47df77a366941497c7a33b1c91768543f0f\n",
      "#10 CACHED\n",
      "\n",
      "#14 [ 9/11] RUN ln -sf /dev/stderr /var/log/nginx/error.log\n",
      "#14 sha256:54e2b9372cbe42f7497de1cc5d92ce8d59dd6ba22b8f5dbe220a55fee7a3c68b\n",
      "#14 CACHED\n",
      "\n",
      "#15 [10/11] COPY code /opt/program\n",
      "#15 sha256:3f61735c147db220e3a66c0119c1c293e9d2a24c83265f6b3a4e13a3f9ca11d2\n",
      "#15 DONE 0.0s\n",
      "\n",
      "#16 [11/11] WORKDIR /opt/program\n",
      "#16 sha256:498ba2f6f245c287ff6e0de08b208b8f98b011f16f25cf58c415f6070c5b7424\n",
      "#16 DONE 0.0s\n",
      "\n",
      "#17 exporting to image\n",
      "#17 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00\n",
      "#17 exporting layers 0.0s done\n",
      "#17 writing image sha256:4cb371140a2649f085605a7de222fdfdfe97d06245d3e80c41b8e322451b61c8 done\n",
      "#17 naming to docker.io/library/whylabs-sagemaker done\n",
      "#17 DONE 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [377983720232.dkr.ecr.us-east-1.amazonaws.com/whylabs-sagemaker]\n",
      "5f70bf18a086: Preparing\n",
      "5fd0815f8e1d: Preparing\n",
      "0db6bc60cf67: Preparing\n",
      "66d55ab066d7: Preparing\n",
      "94df9b81d20b: Preparing\n",
      "1d32553c20b9: Preparing\n",
      "87953760e835: Preparing\n",
      "42fafac3315e: Preparing\n",
      "d20859943999: Preparing\n",
      "cb8615e15e41: Preparing\n",
      "6babb56be259: Preparing\n",
      "42fafac3315e: Waiting\n",
      "d20859943999: Waiting\n",
      "cb8615e15e41: Waiting\n",
      "6babb56be259: Waiting\n",
      "1d32553c20b9: Waiting\n",
      "87953760e835: Waiting\n",
      "0db6bc60cf67: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "66d55ab066d7: Layer already exists\n",
      "94df9b81d20b: Layer already exists\n",
      "87953760e835: Layer already exists\n",
      "d20859943999: Layer already exists\n",
      "1d32553c20b9: Layer already exists\n",
      "42fafac3315e: Layer already exists\n",
      "6babb56be259: Layer already exists\n",
      "cb8615e15e41: Layer already exists\n",
      "5fd0815f8e1d: Pushed\n",
      "latest: digest: sha256:f6b24a578d3cb55c4269545a878b7efe2c28e63de58fbfebc3b290d88ca55064 size: 2615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"./build_push.sh {DOCKER_IMAGE_NAME} {AWS_PROFILE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257c20c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Create SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee265032",
   "metadata": {},
   "source": [
    "The steps to deploy a SageMaker model are:\n",
    "\n",
    "1. Create a model\n",
    "2. Create an endpoint configuration\n",
    "3. Create a SageMaker endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962b697",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='a'></a>\n",
    "### a. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7197f-e9c1-4fe6-889c-0afb78e0431e",
   "metadata": {},
   "source": [
    "**Replace the following Role ARN accordingly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae36031-eb9b-47e7-b937-a292119e910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXECUTION_ROLE_ARN = f\"arn:aws:iam::{AWS_ACCOUNT_ID}:role/SageMakerExecution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECR_IMAGE_URI = f\"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION_NAME}.amazonaws.com/{DOCKER_IMAGE_NAME}:latest\"\n",
    "ENDPOINT_NAME = \"whylabs-sagemaker\"\n",
    "INSTANCE_TYPE = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bac1b",
   "metadata": {},
   "source": [
    "Load variables important for __WhyLabs configuration__ defined inside __.env file__ as dictionary. This values will be settled once the docker container is running within SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce597607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file as dictionary\n",
    "environment = dotenv_values(\"code/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECR image to be used\n",
    "PRIMARY_CONTAINER = {\n",
    "    'Image': ECR_IMAGE_URI, \n",
    "    \"Environment\": environment,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create sagemaker model\n",
    "    r = sm.create_model(\n",
    "        ModelName=ENDPOINT_NAME,\n",
    "        ExecutionRoleArn=EXECUTION_ROLE_ARN,\n",
    "        PrimaryContainer=PRIMARY_CONTAINER,\n",
    "    )\n",
    "    print(\"SageMaker model created.\")\n",
    "except Exception as e:\n",
    "    print(e.response[\"Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce7e7b",
   "metadata": {},
   "source": [
    "<a name='b'></a>\n",
    "### b. Endpoint Config creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f083083",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_CONFIG_NAME = ENDPOINT_NAME + '-config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e850b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # create endpoint configuration\n",
    "    _ = sm.create_endpoint_config(\n",
    "        EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'InstanceType': INSTANCE_TYPE,\n",
    "                'InitialVariantWeight': 1,\n",
    "                'InitialInstanceCount': 1,\n",
    "                'ModelName': ENDPOINT_NAME,\n",
    "                'VariantName': 'AllTraffic'\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(\"Endpoint configuration created.\")\n",
    "except Exception as e:\n",
    "    print(e.response[\"Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66497b8a",
   "metadata": {},
   "source": [
    "<a name='c'></a>\n",
    "### c. Endpoint creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c04791",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # create endpoint\n",
    "    r = sm.create_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        EndpointConfigName=ENDPOINT_CONFIG_NAME\n",
    "    )\n",
    "    print(f\"Completed {ENDPOINT_NAME} model endpoint deployment !!!\")\n",
    "except Exception as e:\n",
    "    print(e.response[\"Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050299b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Test Endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a375d07-1212-4b4e-a56c-d024248d5c61",
   "metadata": {},
   "source": [
    "You have to wait to the model to be in \"InService\" status to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0409282-9b11-4720-9ef3-df61502b8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_random_column_values(data, value: float = np.random.uniform(low=0.0, high=10.0)) -> None:\n",
    "    random_column = None\n",
    "    data_mod = data.copy(deep=True)\n",
    "    try:\n",
    "        number_of_columns = len(data_mod.columns) - 2 # Index and label eliminated\n",
    "        random_column = data_mod.columns[np.random.randint(number_of_columns) + 1]\n",
    "        data_mod[random_column] = value\n",
    "    except Exception as ex:\n",
    "        raise f\"Error adding fix value in random column: {str(random_column)}\"\n",
    "    return data_mod\n",
    "        \n",
    "        \n",
    "def add_random_column_outliers(data, number_outliers: int = 10) -> None:\n",
    "    random_column = None\n",
    "    data_mod = data.copy(deep=True)\n",
    "    try:\n",
    "        number_of_columns = len(data_mod.columns) - 2  # Index and label eliminated\n",
    "        number_of_rows = data_mod.shape[0]\n",
    "        random_column = data_mod.columns[np.random.randint(number_of_columns) + 1]\n",
    "        for i in range(number_outliers):\n",
    "            random_row = np.random.randint(0, number_of_rows)\n",
    "            data_mod.loc[random_row, random_column] = round(np.random.uniform(low=20.0, high=50.0), 2)\n",
    "    except Exception as ex:\n",
    "        raise f\"Error adding outliers in random column: {random_column}\"\n",
    "    return data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f10d8-090a-4c91-934e-959a2386a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"sepal_length_cm\", \"sepal_width_cm\", \"petal_length_cm\", \"petal_width_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d5bd7-8ed3-44e7-bb4e-f89ac3bc0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify a variable distribution\n",
    "data_mod = add_random_column_outliers(data, 30)\n",
    "print(\"Dataset distribution modified!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the endpoint using\n",
    "sg = session.client(\"runtime.sagemaker\", region_name=AWS_REGION_NAME)\n",
    "status = is_endpoint_running(ENDPOINT_NAME, AWS_PROFILE_NAME, AWS_REGION_NAME)\n",
    "# Check if model was created successfully\n",
    "if status == \"InService\":\n",
    "    while True:\n",
    "        # Build a payload with random values\n",
    "        payload = dict(zip(labels, random.choice(data_mod.iloc[:, 0:4].values)))\n",
    "        payload = json.dumps(payload)\n",
    "        # Send payload to sagemaker endpoint\n",
    "        response = sg.invoke_endpoint(\n",
    "            EndpointName=ENDPOINT_NAME,\n",
    "            Body=payload,\n",
    "            ContentType='application/json',\n",
    "        )\n",
    "        # Decode the response\n",
    "        print(json.loads(response[\"Body\"].read().decode(\"utf-8\")))\n",
    "        time.sleep(5)\n",
    "else:\n",
    "    print(f\"Endpoint status is {status}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6eb634-1480-4494-8fdb-83dd3095da31",
   "metadata": {},
   "source": [
    "Response should look like this:\n",
    "```bash\n",
    "{'data': {'class': 'Iris-setosa'}, 'message': 'Success'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807404f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Delete AWS resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = is_endpoint_running(ENDPOINT_NAME, AWS_PROFILE_NAME, AWS_REGION_NAME)\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdfd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if status in [\"InService\", \"Failed\"]:\n",
    "    delete_model(sm, ENDPOINT_NAME)\n",
    "    delete_endpoint_config(sm, ENDPOINT_CONFIG_NAME)\n",
    "    delete_endpoint(sm, ENDPOINT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
