{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### üö© *Create a free WhyLabs account to get more value out of whylogs!*<br> \n",
    ">*Did you know you can store, visualize, and monitor whylogs profiles with the [WhyLabs Observability Platform](https://whylabs.ai/whylogs-free-signup?utm_source=whylogs-Github&utm_medium=whylogs-example&utm_campaign=Writing_Regression_Performance_Metrics_to_WhyLabs)? Sign up for a [free WhyLabs account](https://whylabs.ai/whylogs-free-signup?utm_source=whylogs-Github&utm_medium=whylogs-example&utm_campaign=Writing_Regression_Performance_Metrics_to_WhyLabs) to leverage the power of whylogs and WhyLabs together!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Regression Model Performance Metrics\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/whylabs/whylogs/blob/mainline/python/examples/integrations/writers/Writing_Regression_Performance_Metrics_to_WhyLabs.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll show how you can log performance metrics of your ML Model with whylogs, and how to send it to your dashboard at Whylabs Platform. We'll follow a regression use case, where we're predicting the temperature of a given location based on metereological features.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Download Weather Data for 7 days\n",
    "- Log daily input features with whylogs\n",
    "- Log daily regression performance metrics with whylogs\n",
    "- Write logged profiles to WhyLabs' dashboard\n",
    "- Show performance summary at WhyLabs\n",
    "- __Advanced__: Monitor segmented performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing whylogs\n",
    "\n",
    "First, let's install __whylogs__. Since we want to write to WhyLabs, we'll install the __whylabs__ extra. Additionally, we'll use the __datasets__ module, so let's install it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you may need to restart the kernel to use updated packages.\n",
    "%pip install 'whylogs[whylabs, datasets]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå§Ô∏è The Data - Weather Forecast Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the Weather Forecast Dataset, using whylogs' __Datasets__ module.\n",
    "\n",
    "This dataset contains several meteorological features at a particular place (defined by latitude and longitude features) and time. The task is to predict the temperature based on the input features.\n",
    "\n",
    "The original data is described in [Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks](https://arxiv.org/pdf/2107.07455.pdf), by **Malinin, Andrey, et al.**, and was further transformed to compose the current dataset. You can have more information about the resulting dataset and how to use it at https://whylogs.readthedocs.io/en/latest/datasets/weather.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data into daily batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download 7 batches with 7 days worth of data, corresponding to the last 7 days. We can use directly the __datasets__ module for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whylogs.datasets import Weather\n",
    "from datetime import datetime, timezone, timedelta\n",
    "dataset = Weather()\n",
    "\n",
    "start_timestamp = datetime.now(timezone.utc) - timedelta(days=6)\n",
    "dataset.set_parameters(inference_start_timestamp=start_timestamp)\n",
    "\n",
    "daily_batches = dataset.get_inference_data(number_batches=7)\n",
    "\n",
    "#batches is an iterator, so let's get the list for this\n",
    "daily_batches = list(daily_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this example we're mainly concerned with regression metrics, let's select a subset of the available features, for simplicity.\n",
    "\n",
    "__meta_climate__, __meta_latitude__, __meta_longitude__ will be our input features, while __prediction_temperature__ is the predicted feature given by a trained ML model and the __temperature__ feature is our target.\n",
    "\n",
    "Let's take a look at the data for the first day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_climate</th>\n",
       "      <th>meta_latitude</th>\n",
       "      <th>meta_longitude</th>\n",
       "      <th>prediction_temperature</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00+00:00</th>\n",
       "      <td>mild temperate</td>\n",
       "      <td>38.891300</td>\n",
       "      <td>-6.821330</td>\n",
       "      <td>9.163181</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00+00:00</th>\n",
       "      <td>tropical</td>\n",
       "      <td>12.216667</td>\n",
       "      <td>109.216667</td>\n",
       "      <td>26.220221</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00+00:00</th>\n",
       "      <td>dry</td>\n",
       "      <td>37.991699</td>\n",
       "      <td>-101.746002</td>\n",
       "      <td>13.178478</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00+00:00</th>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-23.333599</td>\n",
       "      <td>-51.130100</td>\n",
       "      <td>23.255124</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00+00:00</th>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-23.479445</td>\n",
       "      <td>-52.012222</td>\n",
       "      <td>27.851674</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             meta_climate  meta_latitude  meta_longitude  \\\n",
       "date                                                                       \n",
       "2022-12-12 00:00:00+00:00  mild temperate      38.891300       -6.821330   \n",
       "2022-12-12 00:00:00+00:00        tropical      12.216667      109.216667   \n",
       "2022-12-12 00:00:00+00:00             dry      37.991699     -101.746002   \n",
       "2022-12-12 00:00:00+00:00  mild temperate     -23.333599      -51.130100   \n",
       "2022-12-12 00:00:00+00:00  mild temperate     -23.479445      -52.012222   \n",
       "\n",
       "                           prediction_temperature  temperature  \n",
       "date                                                            \n",
       "2022-12-12 00:00:00+00:00                9.163181         10.0  \n",
       "2022-12-12 00:00:00+00:00               26.220221         27.0  \n",
       "2022-12-12 00:00:00+00:00               13.178478         15.0  \n",
       "2022-12-12 00:00:00+00:00               23.255124         25.0  \n",
       "2022-12-12 00:00:00+00:00               27.851674         32.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"meta_climate\",\"meta_latitude\",\"meta_longitude\",\"prediction_temperature\",\"temperature\"]\n",
    "df = daily_batches[0].data[columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Setting the Environment Variables\n",
    "\n",
    "In order to send our profile to WhyLabs, let's first set up an account. You can skip this if you already have an account and a model set up.\n",
    "\n",
    "We will need three pieces of information:\n",
    "\n",
    "- API token\n",
    "- Organization ID\n",
    "- Dataset ID (or model-id)\n",
    "\n",
    "Go to https://whylabs.ai/free and grab a free account. You can follow along with the examples if you wish, but if you‚Äôre interested in only following this demonstration, you can go ahead and skip the quick start instructions.\n",
    "\n",
    "After that, you‚Äôll be prompted to create an API token. Once you create it, copy and store it locally. The second important information here is your org ID. Take note of it as well. After you get your API Token and Org ID, you can go to https://hub.whylabsapp.com/models to see your projects dashboard. You can create a new project and take note of it's ID (if it's a model project it will look like `model-xxxx`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WhyLabs Org ID\n",
      "Enter your WhyLabs Dataset ID\n",
      "Enter your WhyLabs API key\n",
      "Using API Key ID:  z8fYdnQwHr\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# set your org-id here - should be something like \"org-xxxx\"\n",
    "print(\"Enter your WhyLabs Org ID\") \n",
    "os.environ[\"WHYLABS_DEFAULT_ORG_ID\"] = input()\n",
    "\n",
    "# set your datased_id (or model_id) here - should be something like \"model-xxxx\"\n",
    "print(\"Enter your WhyLabs Dataset ID\")\n",
    "os.environ[\"WHYLABS_DEFAULT_DATASET_ID\"] = input()\n",
    "\n",
    "\n",
    "# set your API key here\n",
    "print(\"Enter your WhyLabs API key\")\n",
    "os.environ[\"WHYLABS_API_KEY\"] = getpass.getpass()\n",
    "print(\"Using API Key ID: \", os.environ[\"WHYLABS_API_KEY\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Profiling the Data + Sending to WhyLabs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, data is logged by calling `why.log()`. In this case, we'll use `why.log_regression_metrics()`. By setting `log_full_data` to True,  we will log the complete dataframe as in `why.log()`, but additionally it will compute regression metrics and add them to your results. If you want to log only the the `target` and `prediction` columns, without the complete data, you can simply call `log_regression_metrics()` without specifying `log_full_data`, which defaults to False. \n",
    "\n",
    "`log_regression_metrics` takes the complete dataframe as input (with input/output features, as well as your prediction column and target column). We also have to define which column is our target (in this case, `temperature`) and which is our prediction column (`prediction_temperature` in this case).\n",
    "\n",
    "Once the profile is logged, we can set it's timestamp for the proper day as given by our batch's timestamp.\n",
    "\n",
    "Now that we have properly timestamped profiles with regression metrics, we can use the `writer` method to send it to WhyLabs:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: for whylogs versions 1.1.13 and lower, the default behavior of `log_regression_metrics` was logging the complete data, in addition to target and prediction columns. If you were using it in the older versions and wish to keep that behavior when updating whylogs, set `log_full_data` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging data for date 2022-12-13 00:00:00+00:00\n",
      "writing profiles to whylabs...\n",
      "logging data for date 2022-12-14 00:00:00+00:00\n",
      "writing profiles to whylabs...\n",
      "logging data for date 2022-12-15 00:00:00+00:00\n",
      "writing profiles to whylabs...\n",
      "logging data for date 2022-12-16 00:00:00+00:00\n",
      "writing profiles to whylabs...\n",
      "logging data for date 2022-12-17 00:00:00+00:00\n",
      "writing profiles to whylabs...\n",
      "logging data for date 2022-12-18 00:00:00+00:00\n",
      "writing profiles to whylabs...\n",
      "logging data for date 2022-12-19 00:00:00+00:00\n",
      "writing profiles to whylabs...\n"
     ]
    }
   ],
   "source": [
    "from whylogs.api.writer.whylabs import WhyLabsWriter\n",
    "import whylogs as why\n",
    "\n",
    "columns = [\"meta_climate\",\"meta_latitude\",\"meta_longitude\",\"prediction_temperature\",\"temperature\"]\n",
    "for batch in daily_batches:\n",
    "    dataset_timestamp = batch.timestamp\n",
    "\n",
    "    df = batch.data[columns]\n",
    "    print(\"logging data for date {}\".format(dataset_timestamp))\n",
    "    results = why.log_regression_metrics(df, target_column = \"temperature\", prediction_column = \"prediction_temperature\",log_full_data=True)\n",
    "\n",
    "    profile = results.profile()\n",
    "    profile.set_dataset_timestamp(dataset_timestamp)\n",
    "    print(\"writing profiles to whylabs...\")\n",
    "    results.writer(\"whylabs\").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! You just sent your profiles to WhyLabs.\n",
    "\n",
    "At your model's dashboard, you should see the model metrics for the last seven days. For regression, the displayed metrics are:\n",
    "\n",
    "- Total output and input count\n",
    "- Mean Squared Error\n",
    "- Mean Absolute Error\n",
    "- Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/regression_metrics.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage - Monitoring Segmented Performance Metrics\n",
    "\n",
    "You can also log performance metrics for specific segments of your data.\n",
    "\n",
    "For example, let's say we want to monitor the performance of our model according to climate type . We might be interested in comparing performance metrics of the complete data against a specific segment, such as measurements that were taken from stations located at `Dry` or `Tropical` regions.\n",
    "\n",
    "To do that, it's very simple: we just need to specify the column we wish to segment on and pass that information to a __Dataset Schema__ object, like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to learn more about segments, please refer to [this example](https://nbviewer.org/github/whylabs/whylogs/blob/mainline/python/examples/advanced/Segments.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whylogs.core.segmentation_partition import segment_on_column\n",
    "from whylogs.core.schema import DatasetSchema\n",
    "\n",
    "segment_column = \"meta_climate\"\n",
    "segmented_schema = DatasetSchema(segments=segment_on_column(segment_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can log the profiles as demonstraded previously, with two differences. We'll pass the schema to the `log_classification_metrics` method, and also set the timestamp to the complete result set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whylogs.api.writer.whylabs import WhyLabsWriter\n",
    "import whylogs as why\n",
    "\n",
    "columns = [\"meta_climate\",\"meta_latitude\",\"meta_longitude\",\"prediction_temperature\",\"temperature\"]\n",
    "for batch in daily_batches:\n",
    "    dataset_timestamp = batch.timestamp\n",
    "\n",
    "    df = batch.data[columns]\n",
    "    print(\"logging data for date {}\".format(dataset_timestamp))\n",
    "    results = why.log_regression_metrics(\n",
    "        df,\n",
    "        target_column = \"temperature\",\n",
    "        prediction_column = \"prediction_temperature\",\n",
    "        schema=segmented_schema,\n",
    "        log_full_data=True)\n",
    "\n",
    "    results.set_dataset_timestamp(dataset_timestamp)\n",
    "    print(\"writing profiles to whylabs...\")\n",
    "    results.writer(\"whylabs\").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we're passing `segmented_schema` as the `schema` parameter. This will tell whylogs to log the metrics for the complete data, as well as for each segment.\n",
    "\n",
    "You'll get a similar dashboard at the `performance` page at WhyLabs, but now you'll see a dropdown menu with the available segments (or complete data). You'll also be able to choose a second segment to compare against:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/segmented_performance_regression.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the errors seem to be similar between the `tropical` segment and complete data. However, the difference begins to increase with time, with the model's performance for the `tropical` segment being consistently lower than for the complete data. You can verify it by exploring the other metrics on this dashboard, or look for other insights by exploring the other segments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dd5901cadfd4b29c2aaf95ecd29c0c3b10829ad94dcfe59437dbee391154aea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
