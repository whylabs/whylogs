{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### ðŸš© *Create a free WhyLabs account to get more value out of whylogs!*<br> \n",
    ">*Did you know you can store, visualize, and monitor whylogs profiles with the [WhyLabs Observability Platform](https://whylabs.ai/whylogs-free-signup?utm_source=whylogs-Github&utm_medium=whylogs-example&utm_campaign=Embeddings)? Sign up for a [free WhyLabs account](https://whylabs.ai/whylogs-free-signup?utm_source=whylogs-Github&utm_medium=whylogs-example&utm_campaign=Embeddings) to leverage the power of whylogs and WhyLabs together!*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Generic Embeddings Data using Reference Distances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/whylabs/whylogs/blob/mainline/python/examples/experimental/embeddings/Embeddings_Distance_Logging.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High dimensional embedding spaces can be difficult to understand because we often rely on our own subjective judgement of clusters in the space. Often, data scientists try to find issues solely by hovering over individual data points and noting trends in which ones feel out of place.\n",
    "\n",
    "In whylogs, you are able to profile embeddings values by comparing them to reference data points. These references can be completely determined by users (helpful when they represent prototypical \"ideal\" representations of a cluster or scenario) but can also be chosen programmatically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install package extras for whylogs\n",
    "\n",
    "For convenience, we include helper functions to select reference data points for comparing new embedding vectors against. To follow this notebook in full, install the `embeddings` extra (for helper functions) and `viz` extra (for visualizing drift) when installing whylogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Note: you may need to restart the kernel to use updated packages.\n",
    "%pip install --upgrade whylogs[all] -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "### Downloading from OpenML\n",
    "\n",
    "We'll use the 784-dimensional MNIST dataset as our example. This can be downloaded from OpenML via scikit-learn. Because the download can take a few minutes, we suggest saving the data locally as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamie/projects/v1/whylogs/python/.venv/lib/python3.8/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "if os.path.exists(\"mnist_784_X_y.pkl\"):\n",
    "    X, y = pickle.load(open(\"mnist_784_X_y.pkl\", 'rb'))\n",
    "else:\n",
    "    X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training and production datasets\n",
    "\n",
    "Instead of training a model, we'll use the same functionality to split our dataset into an original training dataset and data we'll see in our first day of production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_prod, y_train, y_prod = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "(7000, 785)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "length_of_x = X_prod.shape[0]\n",
    "print(length_of_x)\n",
    "\n",
    "# here we generate some placeholder ids, in practice these could be uuid or some unique string or int\n",
    "ids = np.arange(length_of_x)\n",
    "id_vector_tuples = np.column_stack((ids, X_prod))\n",
    "print(id_vector_tuples.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding references\n",
    "\n",
    "We would like to compare incoming embeddings against up to 30 predefined references. These can chosen by the user either manually or algorithmically. Both reference selection algorithms provided are conducted on raw data, but only for the purposes of finding references itself.\n",
    "\n",
    "#### Manual selection\n",
    "\n",
    "If we had prototypical examples of digits that we wanted to compare our incoming data against, we would collect those data points now.\n",
    "\n",
    "#### Algorithmic selection for labeled data\n",
    "\n",
    "If we have labels for our data, selecting the centroids of clusters for each label makes sense. We provide a helper class, `PCACentroidSelector`, that finds the centroids in PCA space before converting back to the raw 784-dimensional space.\n",
    "\n",
    "Let's utilize the labels available in the dataset for determining our references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whylogs.experimental.preprocess.embeddings.selectors import PCACentroidsSelector\n",
    "\n",
    "references, labels = PCACentroidsSelector(n_components=20).calculate_references(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithmic selection for unlabeled data\n",
    "\n",
    "If we have labels for our data, selecting the centroids of clusters for each label makes sense. We provide a helper class, `PCAKMeansSelector`, that finds the unsupervised centroids in PCA space then converting back to raw space.\n",
    "\n",
    "We'll also calculate these but will elect to use the supervised version for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PCAKMeansSelector is unsupervised; ignoring labels\n",
      "/home/jamie/projects/v1/whylogs/python/.venv/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from whylogs.experimental.preprocess.embeddings.selectors import PCAKMeansSelector\n",
    "\n",
    "unsup_references, unsup_labels = PCAKMeansSelector(n_clusters=8, n_components=20).calculate_references(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling with whylogs\n",
    "\n",
    "As with other advanced features, we can create a `DeclarativeSchema` to tell whylogs to resolve columns of a certain name to the `EmbeddingMetric` that we want to use.\n",
    "\n",
    "We must pass our references, labels, and preferred distance function (either cosine distance or Euclidean distance) as parameters to `EmbeddingConfig` then log as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import whylogs as why\n",
    "from whylogs.core.resolvers import MetricSpec, ResolverSpec\n",
    "from whylogs.core.schema import DeclarativeSchema\n",
    "from whylogs.experimental.extras.embedding_metric import (\n",
    "    DistanceFunction,\n",
    "    EmbeddingConfig,\n",
    "    EmbeddingMetric,\n",
    ")\n",
    "from whylogs.experimental.core.metrics.udf_metric import (\n",
    "    generate_udf_schema,\n",
    "    register_metric_udf,\n",
    ")\n",
    "\n",
    "@register_metric_udf(col_name=\"id_vector_tuple\")\n",
    "def embeddings_outliers(indexed_vectors: Tuple[int, np.ndarray],\n",
    "                        embedding_references = references,\n",
    "                        DISTANCE_THRESHOLD = 850) -> Optional[str]:\n",
    "    from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "    matrix = id_vector_tuples.T[1:]\n",
    "    row_ids = id_vector_tuples.T[0]\n",
    "\n",
    "    # First, make sure single embeddings are in a 2D matrix (1 row, columns = embedding dims)\n",
    "    if len(matrix.shape) == 1:\n",
    "        matrix = matrix.reshape((1, matrix.shape[0]))\n",
    "    outlier_row_ids = []\n",
    "    min_d = None\n",
    "    for i in range(len(row_ids)):\n",
    "        row_id = row_ids[i]\n",
    "        vector = matrix.T[i]\n",
    "        # Get nparray of \n",
    "        reference_distances = euclidean_distances([vector], embedding_references)\n",
    "        if min_d is None:\n",
    "            min_d = reference_distances.min()\n",
    "        else:\n",
    "            min_d = min(min_d, reference_distances.min())\n",
    "        outlier_distances = reference_distances < DISTANCE_THRESHOLD\n",
    "        if outlier_distances.any():\n",
    "            outlier_row_ids.append(row_id)\n",
    "\n",
    "    if outlier_row_ids:\n",
    "        return str(outlier_row_ids)\n",
    "    return min_d\n",
    "\n",
    "config = EmbeddingConfig(\n",
    "    references=references,\n",
    "    labels=labels,\n",
    "    distance_fn=DistanceFunction.euclidean,\n",
    ")\n",
    "schema = DeclarativeSchema(\n",
    "    [ResolverSpec(column_name=\"pixel_values\", metrics=[MetricSpec(EmbeddingMetric, config)])] + generate_udf_schema(),\n",
    ")\n",
    "\n",
    "train_profile = why.log(row={\"pixel_values\": X_train}, schema=schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the contents of our profile measures the distribution of embeddings relative to the references we've provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 distance: mean 2190.804087986482   stddev 202.9271250806984\n",
      "1 distance: mean 2065.1900710071172   stddev 473.02864974704306\n",
      "2 distance: mean 1995.5666316550871   stddev 233.4807738289276\n",
      "3 distance: mean 1998.5577454476095   stddev 274.5659056313274\n",
      "4 distance: mean 1978.138399595618   stddev 304.4965127662653\n",
      "5 distance: mean 1911.848097052227   stddev 254.1624837472048\n",
      "6 distance: mean 2026.1385940336384   stddev 259.55087444579095\n",
      "7 distance: mean 2013.5022809924112   stddev 349.2571781182969\n",
      "8 distance: mean 1936.5924006704263   stddev 263.6855684871088\n",
      "9 distance: mean 1943.798363232508   stddev 329.4170641147685\n"
     ]
    }
   ],
   "source": [
    "train_profile_view = train_profile.view()\n",
    "column = train_profile_view.get_column(\"pixel_values\")\n",
    "summary = column.to_summary_dict()\n",
    "for digit in [str(i) for i in range(10)]:\n",
    "    mean = summary[f'embedding/{digit}_distance:distribution/mean']\n",
    "    stddev = summary[f'embedding/{digit}_distance:distribution/stddev']\n",
    "    print(f\"{digit} distance: mean {mean}   stddev {stddev}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring embeddings drift in WhyLabs\n",
    "\n",
    "This distance approach can be really powerful for measuring drift across new batches of embeddings in a programmatic way using drift metrics as well as the WhyLabs Observability Platform.\n",
    "\n",
    "We'll look at a single example where an engineer introduces a change to reduce the amount of unnecessary processing by filtering out images where more than 90% of pixels are zeros. This is a realistic cleaning step that might be added to an ML pipeline, but will have a detrimental impact on our incoming data, especially the 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which digits have more than or equal to 90% missing\n",
    "not_empty_mask = (X_prod == 0).sum(axis=1) <= (0.9 * 784)\n",
    "X_prod_filtered = X_prod[not_empty_mask]\n",
    "id_vectors_filtered = id_vector_tuples[not_empty_mask]\n",
    "y_prod_filtered = y_prod[not_empty_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log production digits using the same schema\n",
    "prod_profile_view = why.log(row={\"pixel_values\": X_prod_filtered, \"id_vector_tuple\": id_vectors_filtered}, schema=schema).profile().view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'udf/embeddings_outliers:counts/n': 1,\n",
       " 'udf/embeddings_outliers:counts/null': 0,\n",
       " 'udf/embeddings_outliers:counts/nan': 0,\n",
       " 'udf/embeddings_outliers:counts/inf': 0,\n",
       " 'udf/embeddings_outliers:types/integral': 0,\n",
       " 'udf/embeddings_outliers:types/fractional': 0,\n",
       " 'udf/embeddings_outliers:types/boolean': 0,\n",
       " 'udf/embeddings_outliers:types/string': 1,\n",
       " 'udf/embeddings_outliers:types/object': 0,\n",
       " 'udf/embeddings_outliers:types/tensor': 0,\n",
       " 'udf/embeddings_outliers:distribution/mean': 0.0,\n",
       " 'udf/embeddings_outliers:distribution/stddev': 0.0,\n",
       " 'udf/embeddings_outliers:distribution/n': 0,\n",
       " 'udf/embeddings_outliers:distribution/max': nan,\n",
       " 'udf/embeddings_outliers:distribution/min': nan,\n",
       " 'udf/embeddings_outliers:distribution/q_01': None,\n",
       " 'udf/embeddings_outliers:distribution/q_05': None,\n",
       " 'udf/embeddings_outliers:distribution/q_10': None,\n",
       " 'udf/embeddings_outliers:distribution/q_25': None,\n",
       " 'udf/embeddings_outliers:distribution/median': None,\n",
       " 'udf/embeddings_outliers:distribution/q_75': None,\n",
       " 'udf/embeddings_outliers:distribution/q_90': None,\n",
       " 'udf/embeddings_outliers:distribution/q_95': None,\n",
       " 'udf/embeddings_outliers:distribution/q_99': None,\n",
       " 'udf/embeddings_outliers:cardinality/est': 1.0,\n",
       " 'udf/embeddings_outliers:cardinality/upper_1': 1.000049929250618,\n",
       " 'udf/embeddings_outliers:cardinality/lower_1': 1.0,\n",
       " 'udf/embeddings_outliers:frequent_items/frequent_strings': [FrequentItem(value='[1962.0, 2317.0, 3026.0, 3348.0, 4235.0, 4399.0, 4945.0]', est=1, upper=1, lower=1)]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_profile_view.get_column(\"id_vector_tuple\").to_summary_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this using the whylogs profile view's summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 distance difference (target-prod): mean -1.0643165250717175   stddev -3.6655108378841703\n",
      "1 distance difference (target-prod): mean -47.41027240533458   stddev 53.22718190553525\n",
      "2 distance difference (target-prod): mean -8.175996896501147   stddev 2.9526443587183735\n",
      "3 distance difference (target-prod): mean -9.230368340017549   stddev 2.063415827007759\n",
      "4 distance difference (target-prod): mean -6.469144722837655   stddev -4.544108913614707\n",
      "5 distance difference (target-prod): mean -12.712325265648133   stddev 4.2041559907290775\n",
      "6 distance difference (target-prod): mean -12.015676261615454   stddev 0.1252791484623117\n",
      "7 distance difference (target-prod): mean -11.930807147114365   stddev 0.9495908865241063\n",
      "8 distance difference (target-prod): mean -7.396926679449962   stddev 0.36210386386750315\n",
      "9 distance difference (target-prod): mean -8.536834250590118   stddev -2.4705431799656026\n"
     ]
    }
   ],
   "source": [
    "train_profile_summary = train_profile_view.get_column(\"pixel_values\").to_summary_dict()\n",
    "prod_profile_summary = prod_profile_view.get_column(\"pixel_values\").to_summary_dict()\n",
    "for digit in [str(i) for i in range(10)]:\n",
    "    mean_diff = train_profile_summary[f'embedding/{digit}_distance:distribution/mean'] - prod_profile_summary[f'embedding/{digit}_distance:distribution/mean']\n",
    "    stddev_diff = train_profile_summary[f'embedding/{digit}_distance:distribution/stddev'] - prod_profile_summary[f'embedding/{digit}_distance:distribution/stddev']\n",
    "    print(f\"{digit} distance difference (target-prod): mean {mean_diff}   stddev {stddev_diff}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular drift has shown up in the distances to our reference data points as we'd expect. In particular, the 1s seem most affected by our rule.\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "### Upload profiles to WhyLabs for more drift calculations and monitoring\n",
    "\n",
    "See [example notebook](https://whylogs.readthedocs.io/en/stable/examples/integrations/writers/Writing_to_WhyLabs.html) for monitoring your profiles continuously with the WhyLabs Observability Platform.\n",
    "\n",
    "### Exploring other sources of drift\n",
    "\n",
    "Consider comparing this profile to different transformations and subsets of our MNIST dataset: randomly selected subsets of the data, normalized values, missing one or more labels, sorted values, and more.\n",
    "\n",
    "### More example notebooks and documentation\n",
    "\n",
    "Go to the [examples page](https://whylogs.readthedocs.io/en/stable/examples.html) for the complete list of examples!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b95c30731e012b4373e323ecbfabd3cd166cfbf0d931d39f7996a9595914c45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
