:py:mod:`whylogs.api.logger.experimental.logger.actor.process_rolling_logger`
=============================================================================

.. py:module:: whylogs.api.logger.experimental.logger.actor.process_rolling_logger


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.WriterFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.WhyLabsWriterFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.LoggerOptions
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.LoggerFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.ThreadLoggerFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.BaseProcessRollingLogger
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.PipeSignaler
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.ProcessRollingLogger




Attributes
~~~~~~~~~~

.. autoapisummary::

   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.DataTypes
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.DictType
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.BuiltinMessageTypes
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.AdditionalMessages


.. py:data:: DataTypes

   

.. py:data:: DictType

   

.. py:class:: WriterFactory

   .. py:method:: create_writers(dataset_id: str) -> List[whylogs.api.writer.Writer]
      :abstractmethod:



.. py:class:: WhyLabsWriterFactory

   Bases: :py:obj:`WriterFactory`

   .. py:method:: create_writers(dataset_id: str) -> List[whylogs.api.writer.Writer]



.. py:class:: LoggerOptions

   .. py:attribute:: aggregate_by
      :type: whylogs.api.logger.experimental.logger.actor.time_util.TimeGranularity

      

   .. py:attribute:: write_schedule
      :type: Optional[whylogs.api.logger.experimental.logger.actor.time_util.Schedule]

      

   .. py:attribute:: schema
      :type: Optional[whylogs.core.schema.DatasetSchema]

      

   .. py:attribute:: sync_enabled
      :type: bool
      :value: False

      

   .. py:attribute:: current_time_fn
      :type: Optional[Callable[[], int]]

      

   .. py:attribute:: queue_config
      :type: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig

      

   .. py:attribute:: thread_queue_config
      :type: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig

      

   .. py:attribute:: writer_factory
      :type: WriterFactory

      

   .. py:attribute:: queue_type
      :type: whylogs.api.logger.experimental.logger.actor.process_actor.QueueType

      


.. py:class:: LoggerFactory

   .. py:method:: create_logger(dataset_id: str, options: LoggerOptions) -> whylogs.api.logger.experimental.logger.actor.thread_rolling_logger.ThreadRollingLogger
      :abstractmethod:



.. py:class:: ThreadLoggerFactory

   Bases: :py:obj:`LoggerFactory`

   .. py:method:: create_logger(dataset_id: str, options: LoggerOptions) -> whylogs.api.logger.experimental.logger.actor.thread_rolling_logger.ThreadRollingLogger



.. py:data:: BuiltinMessageTypes

   

.. py:data:: AdditionalMessages

   

.. py:class:: BaseProcessRollingLogger(aggregate_by: whylogs.api.logger.experimental.logger.actor.time_util.TimeGranularity = TimeGranularity.Day, write_schedule: Optional[whylogs.api.logger.experimental.logger.actor.time_util.Schedule] = Schedule(cadence=TimeGranularity.Minute, interval=5), schema: Optional[whylogs.core.schema.DatasetSchema] = None, sync_enabled: bool = False, current_time_fn: Optional[Callable[[], int]] = None, queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), thread_queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), writer_factory: WriterFactory = WhyLabsWriterFactory(), queue_type: whylogs.api.logger.experimental.logger.actor.process_actor.QueueType = QueueType.FASTER_FIFO, logger_factory: LoggerFactory = ThreadLoggerFactory())

   Bases: :py:obj:`whylogs.api.logger.experimental.logger.actor.process_actor.ProcessActor`\ [\ :py:obj:`Union`\ [\ :py:obj:`AdditionalMessages`\ , :py:obj:`BuiltinMessageTypes`\ ]\ ], :py:obj:`whylogs.api.logger.experimental.logger.actor.data_logger.DataLogger`\ [\ :py:obj:`whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.ProcessLoggerStatus`\ ], :py:obj:`Generic`\ [\ :py:obj:`AdditionalMessages`\ ]

   Log data asynchronously using a separate process.

   The ProcessRollingLogger is a rolling logger that manages a separate process to do the actual logging. This means
   it logs data over time and periodically uploads it in the background, using a separate process so that it doesn't
   block the main one.

   ```python
   logger = ProcessRollingLogger(
       aggregate_by=TimeGranularity.Day,
       write_schedule=Schedule(cadence=TimeGranularity.Minute, interval=5),
   )

   logger.start()

   logger.log(data_frame)
   ```

   This class mostly wraps and manages several ThreadRollingLoggers that do the real logging with whylogs.

   MAC USERS: You'll run into issues running this on Python>=3.8 because Python will use spawn instead of fork.
   You should be able to get around it by setting the environment variable OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
   in the environment that the process logger runs in, but you can't set it in Python (no using os.environ).

   Most of the arguments that are passed to the underlying loggers are considered the default options for those
   loggers. If you supply a logger_factory then you can override the options for each dataset id's logger.

   :param aggregate_by: The time granularity to aggregate data by. This determines how the time bucketing is done. For
                        the Hour type, the logger will end up pooling data into profiles by the hour.
   :param write_schedule: The schedule to use for writing data. This is used to determine when to upload data.
   :param schema: The DatasetSchema to use for whylogs under the hood.
   :param sync_enabled: Whether to enable synchronous logging. If this is enabled then you can pass log(sync=True) to the
                        log call. Without this you can't use the sync flag.
   :param queue_config: Let's you change various polling and timeout parameters.
   :param thread_queue_config: Same as queue_config, but for the wrapped ThreadRollingLoggers.
   :param writer_factory: The writer factory to use for creating writers.
   :param queue_type: The type of queue to to manage multiprocessing. By default, faster_fifo is used because it's
                      a lot faster than the default multiprocessing queue, but you can use the built in mp.Queue by setting
                      this to QueueType.MP.

   .. py:property:: name


   .. py:property:: daemon

      Return whether process is a daemon

   .. py:property:: authkey


   .. py:property:: exitcode

      Return exit code of process or `None` if it has yet to stop

   .. py:property:: ident

      Return identifier (PID) of process or `None` if it has yet to start

   .. py:property:: sentinel

      Return a file descriptor (Unix) or handle (Windows) suitable for
      waiting for process termination.

   .. py:attribute:: pid

      

   .. py:method:: process_batch(batch: List[Union[AdditionalMessages, BuiltinMessageTypes]], batch_type: Type[Union[AdditionalMessages, BuiltinMessageTypes]]) -> None


   .. py:method:: process_close_message(messages: List[whylogs.api.logger.experimental.logger.actor.actor.CloseMessage]) -> None


   .. py:method:: process_pubsub(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubMessage]) -> None


   .. py:method:: status(timeout: Optional[float] = 1.0) -> whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.ProcessLoggerStatus

      Get the internal status of the logger. Used for diangostics and debugging.
      This is always synchronous and requires the logger to be created with sync_enabled=True.


   .. py:method:: process_pubsub_embedding(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubEmbeddingMessage]) -> None


   .. py:method:: process_log_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogMessage]) -> None


   .. py:method:: process_raw_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogMessage]) -> None


   .. py:method:: process_log_embeddings_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogEmbeddingsMessage]) -> None


   .. py:method:: process_log_embeddings_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogEmbeddingRequestDict]) -> None


   .. py:method:: process_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogRequestDict]) -> None


   .. py:method:: process_flush_message(messages: Optional[List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.FlushMessage]] = None) -> None


   .. py:method:: log(data: whylogs.api.logger.experimental.logger.actor.data_logger.TrackData, timestamp_ms: Optional[int] = None, sync: bool = False, dataset_id: Optional[str] = None) -> None

      Log some data.

      :param data: The data to log. This can either be a pandas data frame, a row (dictionary of str to str/int/float/etc),
                   or a list of rows.
      :param timestamp_ms: The timestamp of the data. If this isn't supplied then it is assumed to have happened now.
      :param sync: Whether or not to perform this action synchronously. By default, this is an asynchronous operation.
                   You can make this synchronous in order to react to errors. Mostly useful when initially setting up
                   logging since the only errors that can be responded to are data format related.


   .. py:method:: flush() -> None

      Flush the internal state, causing everything to be written using the configured writers.


   .. py:method:: run() -> None

      Method to be run in sub-process; can be overridden in sub-class


   .. py:method:: start() -> None

      The process version of the actor apparently has to be manually started after
      it's created, unlike the thread version which can just be automatically started
      from within its init. There must be some post-init setup that needs to be done.


   .. py:method:: close() -> None

      Close the Process object.

      This method releases resources held by the Process object.  It is
      an error to call this method if the child process is still running.


   .. py:method:: close_message_handled() -> bool


   .. py:method:: set_close_message_handled() -> None


   .. py:method:: close_message_wait() -> None


   .. py:method:: is_done() -> bool


   .. py:method:: done_wait() -> None


   .. py:method:: set_done() -> None

      Set this actor as done, meaning it has finished processing all messages.


   .. py:method:: set_closed() -> None

      Sets this actor as closed, meaning it should no longer accept messages.


   .. py:method:: is_closed() -> bool


   .. py:method:: send(message: Union[MessageType, CloseMessage]) -> None


   .. py:method:: send_many(messages: List[Union[MessageType, CloseMessage]]) -> None


   .. py:method:: process_messages() -> None


   .. py:method:: terminate()

      Terminate process; sends SIGTERM signal or uses TerminateProcess()


   .. py:method:: kill()

      Terminate process; sends SIGKILL signal or uses TerminateProcess()


   .. py:method:: join(timeout=None)

      Wait until child process terminates


   .. py:method:: is_alive()

      Return whether process is alive



.. py:class:: PipeSignaler

   Bases: :py:obj:`threading.Thread`

   A thread that listens on a pipe for messages and signals the corresponding futures.

   This class is used in the process logger to enable synchronous logging requests across processes.
   It's essentially a dictionary of futures that are registered by the main process and signaled by the
   child process. A lot of the behavior is implicit because it involves properties of processes, so it's
   worth documenting here.

   - This thread has to be started from the main process, which means it has to be started right before the
       process logger is started (before the os.fork under the hood). It has to be started from the main process
       because the main process will be registering futures on it, and those can't cross the process boundary.
   - The parent and child process each have references to the pipes and they each need to close their references,
       which means close_child has to be called from the child process and close has to be called from the parent.
       Calling close_child in the main processing code will have right effect.
   - The process actor does message batching so multiple ids may be signaled even though a single batch was processed
       because that batch could have contained multiple messages.
   - The signaler uses Events under the hood to know when to stop working. They can be th.Events even though this
       is being used in a multiprocessing environment because nothing the child does can affect them. Keep in mind
       that introducing any behavior on the child side that depends on knowing whether those events are set won't work
       though, they would have to be switched to mp.Events for that.

   This class should really never be used by anyone in most cases. It will just slow down the main process by making
   it wait for logging to complete, but it enables a lot of testing and debugging.

   .. py:property:: name

      A string used for identification purposes only.

      It has no semantics. Multiple threads may be given the same name. The
      initial name is set by the constructor.

   .. py:property:: ident

      Thread identifier of this thread or None if it has not been started.

      This is a nonzero integer. See the get_ident() function. Thread
      identifiers may be recycled when a thread exits and another thread is
      created. The identifier is available even after the thread has exited.

   .. py:property:: daemon

      A boolean value indicating whether this thread is a daemon thread.

      This must be set before start() is called, otherwise RuntimeError is
      raised. Its initial value is inherited from the creating thread; the
      main thread is not a daemon thread and therefore all threads created in
      the main thread default to daemon = False.

      The entire Python program exits when only daemon threads are left.

   .. py:method:: signal(result: Tuple[str, Optional[Exception], Any]) -> None

      Signal that a message was handled by sending a tuple of (message id, exception, data).
      data and exception can be None.
      This should be called from the child process.


   .. py:method:: register(future: Future[Any], message_id: str) -> None

      Register a future to be signaled when the message id is received.
      This should be called from the parent process.


   .. py:method:: run() -> None

      Method representing the thread's activity.

      You may override this method in a subclass. The standard run() method
      invokes the callable object passed to the object's constructor as the
      target argument, if any, with sequential and keyword arguments taken
      from the args and kwargs arguments, respectively.



   .. py:method:: close_child() -> None

      Closes the file descriptors from the child process side.


   .. py:method:: close() -> None

      Closes the thread and all resources. This should be
      called from the parent side.


   .. py:method:: start()

      Start the thread's activity.

      It must be called at most once per thread object. It arranges for the
      object's run() method to be invoked in a separate thread of control.

      This method will raise a RuntimeError if called more than once on the
      same thread object.



   .. py:method:: join(timeout=None)

      Wait until the thread terminates.

      This blocks the calling thread until the thread whose join() method is
      called terminates -- either normally or through an unhandled exception
      or until the optional timeout occurs.

      When the timeout argument is present and not None, it should be a
      floating point number specifying a timeout for the operation in seconds
      (or fractions thereof). As join() always returns None, you must call
      is_alive() after join() to decide whether a timeout happened -- if the
      thread is still alive, the join() call timed out.

      When the timeout argument is not present or None, the operation will
      block until the thread terminates.

      A thread can be join()ed many times.

      join() raises a RuntimeError if an attempt is made to join the current
      thread as that would cause a deadlock. It is also an error to join() a
      thread before it has been started and attempts to do so raises the same
      exception.



   .. py:method:: is_alive()

      Return whether the thread is alive.

      This method returns True just before the run() method starts until just
      after the run() method terminates. See also the module function
      enumerate().



   .. py:method:: isDaemon()


   .. py:method:: setDaemon(daemonic)


   .. py:method:: getName()


   .. py:method:: setName(name)



.. py:class:: ProcessRollingLogger(aggregate_by: whylogs.api.logger.experimental.logger.actor.time_util.TimeGranularity = TimeGranularity.Day, write_schedule: Optional[whylogs.api.logger.experimental.logger.actor.time_util.Schedule] = Schedule(cadence=TimeGranularity.Minute, interval=5), schema: Optional[whylogs.core.schema.DatasetSchema] = None, sync_enabled: bool = False, current_time_fn: Optional[Callable[[], int]] = None, queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), thread_queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), writer_factory: WriterFactory = WhyLabsWriterFactory(), queue_type: whylogs.api.logger.experimental.logger.actor.process_actor.QueueType = QueueType.FASTER_FIFO, logger_factory: LoggerFactory = ThreadLoggerFactory())

   Bases: :py:obj:`BaseProcessRollingLogger`\ [\ :py:obj:`NoReturn`\ ]

   Log data asynchronously using a separate process.

   The ProcessRollingLogger is a rolling logger that manages a separate process to do the actual logging. This means
   it logs data over time and periodically uploads it in the background, using a separate process so that it doesn't
   block the main one.

   ```python
   logger = ProcessRollingLogger(
       aggregate_by=TimeGranularity.Day,
       write_schedule=Schedule(cadence=TimeGranularity.Minute, interval=5),
   )

   logger.start()

   logger.log(data_frame)
   ```

   This class mostly wraps and manages several ThreadRollingLoggers that do the real logging with whylogs.

   MAC USERS: You'll run into issues running this on Python>=3.8 because Python will use spawn instead of fork.
   You should be able to get around it by setting the environment variable OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
   in the environment that the process logger runs in, but you can't set it in Python (no using os.environ).

   Most of the arguments that are passed to the underlying loggers are considered the default options for those
   loggers. If you supply a logger_factory then you can override the options for each dataset id's logger.

   :param aggregate_by: The time granularity to aggregate data by. This determines how the time bucketing is done. For
                        the Hour type, the logger will end up pooling data into profiles by the hour.
   :param write_schedule: The schedule to use for writing data. This is used to determine when to upload data.
   :param schema: The DatasetSchema to use for whylogs under the hood.
   :param sync_enabled: Whether to enable synchronous logging. If this is enabled then you can pass log(sync=True) to the
                        log call. Without this you can't use the sync flag.
   :param queue_config: Let's you change various polling and timeout parameters.
   :param thread_queue_config: Same as queue_config, but for the wrapped ThreadRollingLoggers.
   :param writer_factory: The writer factory to use for creating writers.
   :param queue_type: The type of queue to to manage multiprocessing. By default, faster_fifo is used because it's
                      a lot faster than the default multiprocessing queue, but you can use the built in mp.Queue by setting
                      this to QueueType.MP.

   .. py:property:: name


   .. py:property:: daemon

      Return whether process is a daemon

   .. py:property:: authkey


   .. py:property:: exitcode

      Return exit code of process or `None` if it has yet to stop

   .. py:property:: ident

      Return identifier (PID) of process or `None` if it has yet to start

   .. py:property:: sentinel

      Return a file descriptor (Unix) or handle (Windows) suitable for
      waiting for process termination.

   .. py:attribute:: pid

      

   .. py:method:: process_batch(batch: List[Union[AdditionalMessages, BuiltinMessageTypes]], batch_type: Type[Union[AdditionalMessages, BuiltinMessageTypes]]) -> None


   .. py:method:: process_close_message(messages: List[whylogs.api.logger.experimental.logger.actor.actor.CloseMessage]) -> None


   .. py:method:: process_pubsub(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubMessage]) -> None


   .. py:method:: status(timeout: Optional[float] = 1.0) -> whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.ProcessLoggerStatus

      Get the internal status of the logger. Used for diangostics and debugging.
      This is always synchronous and requires the logger to be created with sync_enabled=True.


   .. py:method:: process_pubsub_embedding(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubEmbeddingMessage]) -> None


   .. py:method:: process_log_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogMessage]) -> None


   .. py:method:: process_raw_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogMessage]) -> None


   .. py:method:: process_log_embeddings_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogEmbeddingsMessage]) -> None


   .. py:method:: process_log_embeddings_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogEmbeddingRequestDict]) -> None


   .. py:method:: process_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogRequestDict]) -> None


   .. py:method:: process_flush_message(messages: Optional[List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.FlushMessage]] = None) -> None


   .. py:method:: log(data: whylogs.api.logger.experimental.logger.actor.data_logger.TrackData, timestamp_ms: Optional[int] = None, sync: bool = False, dataset_id: Optional[str] = None) -> None

      Log some data.

      :param data: The data to log. This can either be a pandas data frame, a row (dictionary of str to str/int/float/etc),
                   or a list of rows.
      :param timestamp_ms: The timestamp of the data. If this isn't supplied then it is assumed to have happened now.
      :param sync: Whether or not to perform this action synchronously. By default, this is an asynchronous operation.
                   You can make this synchronous in order to react to errors. Mostly useful when initially setting up
                   logging since the only errors that can be responded to are data format related.


   .. py:method:: flush() -> None

      Flush the internal state, causing everything to be written using the configured writers.


   .. py:method:: run() -> None

      Method to be run in sub-process; can be overridden in sub-class


   .. py:method:: start() -> None

      The process version of the actor apparently has to be manually started after
      it's created, unlike the thread version which can just be automatically started
      from within its init. There must be some post-init setup that needs to be done.


   .. py:method:: close() -> None

      Close the Process object.

      This method releases resources held by the Process object.  It is
      an error to call this method if the child process is still running.


   .. py:method:: close_message_handled() -> bool


   .. py:method:: set_close_message_handled() -> None


   .. py:method:: close_message_wait() -> None


   .. py:method:: is_done() -> bool


   .. py:method:: done_wait() -> None


   .. py:method:: set_done() -> None

      Set this actor as done, meaning it has finished processing all messages.


   .. py:method:: set_closed() -> None

      Sets this actor as closed, meaning it should no longer accept messages.


   .. py:method:: is_closed() -> bool


   .. py:method:: send(message: Union[MessageType, CloseMessage]) -> None


   .. py:method:: send_many(messages: List[Union[MessageType, CloseMessage]]) -> None


   .. py:method:: process_messages() -> None


   .. py:method:: terminate()

      Terminate process; sends SIGTERM signal or uses TerminateProcess()


   .. py:method:: kill()

      Terminate process; sends SIGKILL signal or uses TerminateProcess()


   .. py:method:: join(timeout=None)

      Wait until child process terminates


   .. py:method:: is_alive()

      Return whether process is alive



