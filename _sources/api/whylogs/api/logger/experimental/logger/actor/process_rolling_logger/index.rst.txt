:py:mod:`whylogs.api.logger.experimental.logger.actor.process_rolling_logger`
=============================================================================

.. py:module:: whylogs.api.logger.experimental.logger.actor.process_rolling_logger


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.WriterFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.WhyLabsWriterFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.LoggerOptions
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.LoggerFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.ThreadLoggerFactory
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.BaseProcessRollingLogger
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.ProcessRollingLogger




Attributes
~~~~~~~~~~

.. autoapisummary::

   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.DataTypes
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.DictType
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.BuiltinMessageTypes
   whylogs.api.logger.experimental.logger.actor.process_rolling_logger.AdditionalMessages


.. py:data:: DataTypes

   

.. py:data:: DictType

   

.. py:class:: WriterFactory

   .. py:method:: create_writers(dataset_id: str) -> List[whylogs.api.writer.Writer]
      :abstractmethod:



.. py:class:: WhyLabsWriterFactory

   Bases: :py:obj:`WriterFactory`

   .. py:method:: create_writers(dataset_id: str) -> List[whylogs.api.writer.Writer]



.. py:class:: LoggerOptions

   .. py:attribute:: aggregate_by
      :type: whylogs.api.logger.experimental.logger.actor.time_util.TimeGranularity

      

   .. py:attribute:: write_schedule
      :type: Optional[whylogs.api.logger.experimental.logger.actor.time_util.Schedule]

      

   .. py:attribute:: schema
      :type: Optional[whylogs.core.schema.DatasetSchema]

      

   .. py:attribute:: sync_enabled
      :type: bool
      :value: False

      

   .. py:attribute:: current_time_fn
      :type: Optional[Callable[[], int]]

      

   .. py:attribute:: queue_config
      :type: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig

      

   .. py:attribute:: thread_queue_config
      :type: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig

      

   .. py:attribute:: writer_factory
      :type: WriterFactory

      

   .. py:attribute:: queue_type
      :type: whylogs.api.logger.experimental.logger.actor.process_actor.QueueType

      


.. py:class:: LoggerFactory

   .. py:method:: create_logger(dataset_id: str, options: LoggerOptions) -> whylogs.api.logger.experimental.logger.actor.thread_rolling_logger.ThreadRollingLogger
      :abstractmethod:



.. py:class:: ThreadLoggerFactory

   Bases: :py:obj:`LoggerFactory`

   .. py:method:: create_logger(dataset_id: str, options: LoggerOptions) -> whylogs.api.logger.experimental.logger.actor.thread_rolling_logger.ThreadRollingLogger



.. py:data:: BuiltinMessageTypes

   

.. py:data:: AdditionalMessages

   

.. py:class:: BaseProcessRollingLogger(aggregate_by: whylogs.api.logger.experimental.logger.actor.time_util.TimeGranularity = TimeGranularity.Day, write_schedule: Optional[whylogs.api.logger.experimental.logger.actor.time_util.Schedule] = Schedule(cadence=TimeGranularity.Minute, interval=5), schema: Optional[whylogs.core.schema.DatasetSchema] = None, sync_enabled: bool = False, current_time_fn: Optional[Callable[[], int]] = None, queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), thread_queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), writer_factory: WriterFactory = WhyLabsWriterFactory(), queue_type: whylogs.api.logger.experimental.logger.actor.process_actor.QueueType = QueueType.FASTER_FIFO, logger_factory: LoggerFactory = ThreadLoggerFactory())

   Bases: :py:obj:`whylogs.api.logger.experimental.logger.actor.process_actor.ProcessActor`\ [\ :py:obj:`Union`\ [\ :py:obj:`AdditionalMessages`\ , :py:obj:`BuiltinMessageTypes`\ ]\ , :py:obj:`Union`\ [\ :py:obj:`whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.ProcessLoggerStatus`\ , :py:obj:`whylogs.api.logger.experimental.logger.actor.thread_rolling_logger.LoggerStatus`\ , :py:obj:`None`\ ]\ ], :py:obj:`whylogs.api.logger.experimental.logger.actor.data_logger.DataLogger`\ [\ :py:obj:`Union`\ [\ :py:obj:`whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.ProcessLoggerStatus`\ , :py:obj:`whylogs.api.logger.experimental.logger.actor.thread_rolling_logger.LoggerStatus`\ , :py:obj:`None`\ ]\ ], :py:obj:`Generic`\ [\ :py:obj:`AdditionalMessages`\ ]

   Log data asynchronously using a separate process.

   The ProcessRollingLogger is a rolling logger that manages a separate process to do the actual logging. This means
   it logs data over time and periodically uploads it in the background, using a separate process so that it doesn't
   block the main one.

   ```python
   logger = ProcessRollingLogger(
       aggregate_by=TimeGranularity.Day,
       write_schedule=Schedule(cadence=TimeGranularity.Minute, interval=5),
   )

   logger.start()

   logger.log(data_frame)
   ```

   This class mostly wraps and manages several ThreadRollingLoggers that do the real logging with whylogs.

   MAC USERS: You'll run into issues running this on Python>=3.8 because Python will use spawn instead of fork.
   You should be able to get around it by setting the environment variable OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
   in the environment that the process logger runs in, but you can't set it in Python (no using os.environ).

   Most of the arguments that are passed to the underlying loggers are considered the default options for those
   loggers. If you supply a logger_factory then you can override the options for each dataset id's logger.

   :param aggregate_by: The time granularity to aggregate data by. This determines how the time bucketing is done. For
                        the Hour type, the logger will end up pooling data into profiles by the hour.
   :param write_schedule: The schedule to use for writing data. This is used to determine when to upload data.
   :param schema: The DatasetSchema to use for whylogs under the hood.
   :param sync_enabled: Whether to enable synchronous logging. If this is enabled then you can pass log(sync=True) to the
                        log call. Without this you can't use the sync flag.
   :param queue_config: Let's you change various polling and timeout parameters.
   :param thread_queue_config: Same as queue_config, but for the wrapped ThreadRollingLoggers.
   :param writer_factory: The writer factory to use for creating writers.
   :param queue_type: The type of queue to to manage multiprocessing. By default, faster_fifo is used because it's
                      a lot faster than the default multiprocessing queue, but you can use the built in mp.Queue by setting
                      this to QueueType.MP.

   .. py:property:: name


   .. py:property:: daemon

      Return whether process is a daemon

   .. py:property:: authkey


   .. py:property:: exitcode

      Return exit code of process or `None` if it has yet to stop

   .. py:property:: ident

      Return identifier (PID) of process or `None` if it has yet to start

   .. py:property:: sentinel

      Return a file descriptor (Unix) or handle (Windows) suitable for
      waiting for process termination.

   .. py:attribute:: pid

      

   .. py:method:: process_batch(batch: List[Union[AdditionalMessages, BuiltinMessageTypes]], batch_type: Type[Union[AdditionalMessages, BuiltinMessageTypes]]) -> None


   .. py:method:: process_close_message(messages: List[whylogs.api.logger.experimental.logger.actor.actor.CloseMessage]) -> None


   .. py:method:: process_pubsub(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubMessage]) -> None


   .. py:method:: process_pubsub_embedding(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubEmbeddingMessage]) -> None


   .. py:method:: process_log_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogMessage]) -> None


   .. py:method:: process_raw_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogMessage]) -> None


   .. py:method:: process_log_embeddings_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogEmbeddingsMessage]) -> None


   .. py:method:: process_log_embeddings_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogEmbeddingRequestDict]) -> None


   .. py:method:: process_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogRequestDict]) -> None


   .. py:method:: process_flush_message(messages: Optional[List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.FlushMessage]] = None) -> None


   .. py:method:: log(data: whylogs.api.logger.experimental.logger.actor.data_logger.TrackData, timestamp_ms: Optional[int] = None, sync: bool = False, dataset_id: Optional[str] = None) -> None

      Log some data.

      :param data: The data to log. This can either be a pandas data frame, a row (dictionary of str to str/int/float/etc),
                   or a list of rows.
      :param timestamp_ms: The timestamp of the data. If this isn't supplied then it is assumed to have happened now.
      :param sync: Whether or not to perform this action synchronously. By default, this is an asynchronous operation.
                   You can make this synchronous in order to react to errors. Mostly useful when initially setting up
                   logging since the only errors that can be responded to are data format related.


   .. py:method:: flush() -> None

      Flush the internal state, causing everything to be written using the configured writers.


   .. py:method:: run() -> None

      Method to be run in sub-process; can be overridden in sub-class


   .. py:method:: start() -> None

      The process version of the actor apparently has to be manually started after
      it's created, unlike the thread version which can just be automatically started
      from within its init. There must be some post-init setup that needs to be done.


   .. py:method:: close() -> None

      Close the Process object.

      This method releases resources held by the Process object.  It is
      an error to call this method if the child process is still running.


   .. py:method:: close_message_handled() -> bool


   .. py:method:: set_close_message_handled() -> None


   .. py:method:: close_message_wait() -> None


   .. py:method:: is_done() -> bool


   .. py:method:: done_wait() -> None


   .. py:method:: set_done() -> None

      Set this actor as done, meaning it has finished processing all messages.


   .. py:method:: set_closed() -> None

      Sets this actor as closed, meaning it should no longer accept messages.


   .. py:method:: is_closed() -> bool


   .. py:method:: status(timeout: Optional[float] = 1.0) -> StatusType

      Get the internal status of the Process Actor. Used for diagnostics and debugging.
      This is always synchronous and requires the ProcessActor to be created with sync_enabled=True.


   .. py:method:: send(message: Union[MessageType, CloseMessage]) -> None


   .. py:method:: send_many(messages: List[Union[MessageType, CloseMessage]]) -> None


   .. py:method:: process_messages() -> None


   .. py:method:: terminate()

      Terminate process; sends SIGTERM signal or uses TerminateProcess()


   .. py:method:: kill()

      Terminate process; sends SIGKILL signal or uses TerminateProcess()


   .. py:method:: join(timeout=None)

      Wait until child process terminates


   .. py:method:: is_alive()

      Return whether process is alive



.. py:class:: ProcessRollingLogger(aggregate_by: whylogs.api.logger.experimental.logger.actor.time_util.TimeGranularity = TimeGranularity.Day, write_schedule: Optional[whylogs.api.logger.experimental.logger.actor.time_util.Schedule] = Schedule(cadence=TimeGranularity.Minute, interval=5), schema: Optional[whylogs.core.schema.DatasetSchema] = None, sync_enabled: bool = False, current_time_fn: Optional[Callable[[], int]] = None, queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), thread_queue_config: whylogs.api.logger.experimental.logger.actor.actor.QueueConfig = QueueConfig(), writer_factory: WriterFactory = WhyLabsWriterFactory(), queue_type: whylogs.api.logger.experimental.logger.actor.process_actor.QueueType = QueueType.FASTER_FIFO, logger_factory: LoggerFactory = ThreadLoggerFactory())

   Bases: :py:obj:`BaseProcessRollingLogger`\ [\ :py:obj:`NoReturn`\ ]

   Log data asynchronously using a separate process.

   The ProcessRollingLogger is a rolling logger that manages a separate process to do the actual logging. This means
   it logs data over time and periodically uploads it in the background, using a separate process so that it doesn't
   block the main one.

   ```python
   logger = ProcessRollingLogger(
       aggregate_by=TimeGranularity.Day,
       write_schedule=Schedule(cadence=TimeGranularity.Minute, interval=5),
   )

   logger.start()

   logger.log(data_frame)
   ```

   This class mostly wraps and manages several ThreadRollingLoggers that do the real logging with whylogs.

   MAC USERS: You'll run into issues running this on Python>=3.8 because Python will use spawn instead of fork.
   You should be able to get around it by setting the environment variable OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
   in the environment that the process logger runs in, but you can't set it in Python (no using os.environ).

   Most of the arguments that are passed to the underlying loggers are considered the default options for those
   loggers. If you supply a logger_factory then you can override the options for each dataset id's logger.

   :param aggregate_by: The time granularity to aggregate data by. This determines how the time bucketing is done. For
                        the Hour type, the logger will end up pooling data into profiles by the hour.
   :param write_schedule: The schedule to use for writing data. This is used to determine when to upload data.
   :param schema: The DatasetSchema to use for whylogs under the hood.
   :param sync_enabled: Whether to enable synchronous logging. If this is enabled then you can pass log(sync=True) to the
                        log call. Without this you can't use the sync flag.
   :param queue_config: Let's you change various polling and timeout parameters.
   :param thread_queue_config: Same as queue_config, but for the wrapped ThreadRollingLoggers.
   :param writer_factory: The writer factory to use for creating writers.
   :param queue_type: The type of queue to to manage multiprocessing. By default, faster_fifo is used because it's
                      a lot faster than the default multiprocessing queue, but you can use the built in mp.Queue by setting
                      this to QueueType.MP.

   .. py:property:: name


   .. py:property:: daemon

      Return whether process is a daemon

   .. py:property:: authkey


   .. py:property:: exitcode

      Return exit code of process or `None` if it has yet to stop

   .. py:property:: ident

      Return identifier (PID) of process or `None` if it has yet to start

   .. py:property:: sentinel

      Return a file descriptor (Unix) or handle (Windows) suitable for
      waiting for process termination.

   .. py:attribute:: pid

      

   .. py:method:: process_batch(batch: List[Union[AdditionalMessages, BuiltinMessageTypes]], batch_type: Type[Union[AdditionalMessages, BuiltinMessageTypes]]) -> None


   .. py:method:: process_close_message(messages: List[whylogs.api.logger.experimental.logger.actor.actor.CloseMessage]) -> None


   .. py:method:: process_pubsub(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubMessage]) -> None


   .. py:method:: process_pubsub_embedding(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawPubSubEmbeddingMessage]) -> None


   .. py:method:: process_log_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogMessage]) -> None


   .. py:method:: process_raw_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogMessage]) -> None


   .. py:method:: process_log_embeddings_messages(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.RawLogEmbeddingsMessage]) -> None


   .. py:method:: process_log_embeddings_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogEmbeddingRequestDict]) -> None


   .. py:method:: process_log_dicts(messages: List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.LogRequestDict]) -> None


   .. py:method:: process_flush_message(messages: Optional[List[whylogs.api.logger.experimental.logger.actor.process_rolling_logger_messages.FlushMessage]] = None) -> None


   .. py:method:: log(data: whylogs.api.logger.experimental.logger.actor.data_logger.TrackData, timestamp_ms: Optional[int] = None, sync: bool = False, dataset_id: Optional[str] = None) -> None

      Log some data.

      :param data: The data to log. This can either be a pandas data frame, a row (dictionary of str to str/int/float/etc),
                   or a list of rows.
      :param timestamp_ms: The timestamp of the data. If this isn't supplied then it is assumed to have happened now.
      :param sync: Whether or not to perform this action synchronously. By default, this is an asynchronous operation.
                   You can make this synchronous in order to react to errors. Mostly useful when initially setting up
                   logging since the only errors that can be responded to are data format related.


   .. py:method:: flush() -> None

      Flush the internal state, causing everything to be written using the configured writers.


   .. py:method:: run() -> None

      Method to be run in sub-process; can be overridden in sub-class


   .. py:method:: start() -> None

      The process version of the actor apparently has to be manually started after
      it's created, unlike the thread version which can just be automatically started
      from within its init. There must be some post-init setup that needs to be done.


   .. py:method:: close() -> None

      Close the Process object.

      This method releases resources held by the Process object.  It is
      an error to call this method if the child process is still running.


   .. py:method:: close_message_handled() -> bool


   .. py:method:: set_close_message_handled() -> None


   .. py:method:: close_message_wait() -> None


   .. py:method:: is_done() -> bool


   .. py:method:: done_wait() -> None


   .. py:method:: set_done() -> None

      Set this actor as done, meaning it has finished processing all messages.


   .. py:method:: set_closed() -> None

      Sets this actor as closed, meaning it should no longer accept messages.


   .. py:method:: is_closed() -> bool


   .. py:method:: status(timeout: Optional[float] = 1.0) -> StatusType

      Get the internal status of the Process Actor. Used for diagnostics and debugging.
      This is always synchronous and requires the ProcessActor to be created with sync_enabled=True.


   .. py:method:: send(message: Union[MessageType, CloseMessage]) -> None


   .. py:method:: send_many(messages: List[Union[MessageType, CloseMessage]]) -> None


   .. py:method:: process_messages() -> None


   .. py:method:: terminate()

      Terminate process; sends SIGTERM signal or uses TerminateProcess()


   .. py:method:: kill()

      Terminate process; sends SIGKILL signal or uses TerminateProcess()


   .. py:method:: join(timeout=None)

      Wait until child process terminates


   .. py:method:: is_alive()

      Return whether process is alive



